- 优点：
    - 1.简单有效
    - 2.没有模型,每次运行都要重新训练,重新训练代价低,但这不意味着计算量小
    - 3.适合类域交叉样本,KNN方法主要靠周围有限的邻近的样本,因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。
    - 4.在数据量比较大的时候,效果比较好;数据量小容易误分。

- 缺点:
    - 1.没有得到模型,每次都要重新计算
    - 2.类别评分不是规格化,不是得到一个概率
    - 3.结果解释性不强
    - 4.在不均衡样本上效果不好.
    - 5.需要计算样本间的距离,计算量比较大.